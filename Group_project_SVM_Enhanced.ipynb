{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c3c9d9d-dba2-42cd-a294-f8d79aef4bb2",
   "metadata": {},
   "source": [
    "## 1. Dataset Description & Feature Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5cc329-736f-4f06-8272-557a988c1116",
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit\nfrom sklearn.preprocessing import StandardScaler, label_binarize\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import (classification_report, confusion_matrix, ConfusionMatrixDisplay, \n                             roc_curve, auc, accuracy_score, f1_score, roc_auc_score,\n                             average_precision_score, make_scorer)\nfrom sklearn.base import clone\nfrom itertools import cycle\n\nwarnings.filterwarnings('ignore')\nsns.set(style=\"whitegrid\")\n\n# Configuration\nDATE_COL = \"date\"\nSPLIT_DATE = \"2022-01-01\"\nRANDOM_STATE = 42\n\n# Load Dataset\ndf = pd.read_csv('master_dataset_ml_ready_labelled.csv')\ndf[DATE_COL] = pd.to_datetime(df[DATE_COL], errors='coerce')\ndf = df.sort_values(by=DATE_COL).reset_index(drop=True)\n\n# Dataset Description\ndescription = \"\"\"\n### Dataset Feature Explanation:\n- **Date**: The observation date (Daily frequency).\n- **CDD (Cooling Degree Days)**: TX, PA, IL, NY - Measures demand for cooling (electricity/gas) based on heat.\n- **HDD (Heating Degree Days)**: TX, PA, IL, NY - Measures demand for heating (gas) based on cold.\n- **contract_1_price / contract_2_price**: Front-month and second-month futures prices for natural gas.\n- **spot_price**: The current physical market price for natural gas.\n- **storage_bcf**: US natural gas storage levels in Billion Cubic Feet (Key supply indicator).\n- **us_gas_rigs**: Number of active gas drilling rigs (Future supply indicator).\n- **Time Features**: Year, Month, Day of Year, Day of Week, Quarter - Captured to model seasonality.\n\n### Enhanced Features (Added):\n- **curve_spread**: Futures curve shape (contract_2 - contract_1)\n- **storage_bcf_change_7d**: 7-day storage delta\n- **HDD_total / CDD_total**: Aggregated weather indicators\n- **net_weather**: HDD_total - CDD_total\n- **ret_1, ret_3, ret_5, ret_10**: Momentum indicators (lagged returns)\n\n### Target (Binary):\n- **PriceUp**: 1 if next day's price increases, 0 otherwise\n\"\"\"\nprint(description)\ndf.head()"
  },
  {
   "cell_type": "markdown",
   "id": "efd577bd-6bfb-40b7-8ccc-373670f0e1eb",
   "metadata": {},
   "source": "## 2. Feature Engineering & Exploratory Data Analysis (EDA)\n\nThis section creates engineered features (matching the SGD notebook approach) and visualizes the data:\n- **Binary Target**: PriceUp (1 if next day's return > 0)\n- **Curve Spread**: Futures curve shape indicator\n- **Storage Change**: 7-day delta in storage levels\n- **Aggregated Weather**: HDD_total, CDD_total, net_weather\n- **Momentum Features**: ret_1, ret_3, ret_5, ret_10 (lagged returns)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658e6841-b2a5-419a-8809-076d7cd1fa3a",
   "metadata": {},
   "outputs": [],
   "source": "# --- Feature Engineering ---\n# 1. Target: Binary Next-Day Direction (PriceUp)\ndf['return'] = df['spot_price'].pct_change()\ndf['PriceUp'] = (df['return'].shift(-1) > 0).astype(int)\n\n# 2. Synthetic Features\n# A. Curve Spread (Futures curve shape)\ndf['curve_spread'] = df['contract_2_price'] - df['contract_1_price']\n\n# B. Storage Change (7-day delta)\ndf['storage_bcf_change_7d'] = df['storage_bcf'].diff(7)\n\n# C. Aggregated Weather\nhdd_cols = [c for c in df.columns if c.startswith('HDD_')]\ncdd_cols = [c for c in df.columns if c.startswith('CDD_')]\n\ndf['HDD_total'] = df[hdd_cols].mean(axis=1)\ndf['CDD_total'] = df[cdd_cols].mean(axis=1)\ndf['net_weather'] = df['HDD_total'] - df['CDD_total']\n\n# D. Momentum / Returns Features\ndf['ret_1'] = df['return'].shift(1)       # Yesterday's return\ndf['ret_3'] = df['return'].rolling(3).mean()\ndf['ret_5'] = df['return'].rolling(5).mean()\ndf['ret_10'] = df['return'].rolling(10).mean()\n\n# 3. Cleanup - Drop rows with NaNs created by lags/rolling/target shift\ninitial_shape = df.shape\ndf.dropna(inplace=True)\nprint(f\"Dropped {initial_shape[0] - df.shape[0]} rows due to lag/rolling NaN creation.\")\n\n# 1. Target Class Distribution (Binary)\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\nax1 = axes[0]\nsns.countplot(x='PriceUp', data=df, palette='viridis', ax=ax1)\nax1.set_title('Distribution of Binary Target (PriceUp)', fontsize=15)\nax1.set_xlabel('PriceUp (0: Down/Neutral, 1: Up)')\nax1.set_ylabel('Frequency')\n\n# Show class balance percentages\ntotal = len(df)\nfor p in ax1.patches:\n    height = p.get_height()\n    ax1.annotate(f'{height/total:.1%}', (p.get_x() + p.get_width()/2., height),\n                ha='center', va='bottom', fontsize=12)\n\n# 2. Correlation Analysis (including new features)\nax2 = axes[1]\nnew_features = ['curve_spread', 'storage_bcf_change_7d', 'HDD_total', 'CDD_total', \n                'net_weather', 'ret_1', 'ret_3', 'ret_5', 'ret_10', 'PriceUp']\ncorr_new = df[new_features].corr()\nsns.heatmap(corr_new, annot=True, fmt='.2f', cmap='coolwarm', center=0, ax=ax2)\nax2.set_title('Engineered Features Correlation', fontsize=14)\nplt.tight_layout()\nplt.show()\n\n# 3. Supply vs Price Trend (Sample)\nplt.figure(figsize=(12, 6))\nsns.lineplot(data=df, x='storage_bcf', y='spot_price', hue='PriceUp')\nplt.title('Relationship between Storage Levels and Spot Price', fontsize=14)\nplt.show()\n\nprint(\"\\nNew Binary Target Distribution (PriceUp):\")\nprint(df['PriceUp'].value_counts(normalize=True))"
  },
  {
   "cell_type": "markdown",
   "id": "ad116f55-f8de-43e1-99b3-19f5e6d548ad",
   "metadata": {},
   "source": "## 3. Pre-processing and Chronological Split\n\nUsing chronological (time-based) split instead of random split for proper time-series evaluation.\n- Train: Data before 2022-01-01\n- Test: Data from 2022-01-01 onwards"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f83aab-d44e-4ccc-97ad-0edb92fce934",
   "metadata": {},
   "outputs": [],
   "source": "# Define columns to DROP (leakage and non-predictive)\ncols_to_drop = [\n    DATE_COL, \n    'PriceUp',\n    'spot_price',  # Drop to avoid leakage (target is derived from this)\n    'price_movement_scaled', \n    'price_movement_raw', \n    'return'  # This is basically the target, just unshifted\n]\n\n# Prepare features and target\nX = df.drop(columns=cols_to_drop, errors='ignore')\ny = df['PriceUp']\n\n# Ensure X is strictly numeric\nX = X.select_dtypes(include=[np.number])\n\nprint(f\"Final Feature Set ({X.shape[1]} features):\")\nprint(list(X.columns))\n\n# Chronological Split at 2022-01-01 (proper for time-series data)\nmask_train = df[DATE_COL] < SPLIT_DATE\nmask_test = df[DATE_COL] >= SPLIT_DATE\n\nX_train, X_test = X[mask_train], X[mask_test]\ny_train, y_test = y[mask_train], y[mask_test]\n\nprint(f\"\\nTrain Dates: < {SPLIT_DATE} | Shape: {X_train.shape}\")\nprint(f\"Test Dates: >= {SPLIT_DATE} | Shape: {X_test.shape}\")\n\n# Feature Scaling\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nprint(f\"\\nClass distribution in training set:\")\nprint(y_train.value_counts(normalize=True))\nprint(f\"\\nClass distribution in test set:\")\nprint(y_test.value_counts(normalize=True))"
  },
  {
   "cell_type": "markdown",
   "id": "7859a4bb-9ed6-40c9-a2e4-3d5921eb485f",
   "metadata": {},
   "source": [
    "## 4: Training SVM Baseline Model (Unoptimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87290562-d48a-4718-8afa-3f412ee28426",
   "metadata": {},
   "outputs": [],
   "source": "# 1. Initialize SVM Baseline Model\nsvm_model = SVC(probability=True, random_state=RANDOM_STATE)\n    \nprint(\"--- Training Baseline SVM Model ---\")\n\n# Train\nsvm_model.fit(X_train_scaled, y_train)\n\n# Predict\ny_pred_baseline = svm_model.predict(X_test_scaled)\ny_probs_baseline = svm_model.predict_proba(X_test_scaled)[:, 1]\n\n# Multi-Metric Evaluation\nbaseline_acc = accuracy_score(y_test, y_pred_baseline)\nbaseline_f1 = f1_score(y_test, y_pred_baseline, pos_label=1)\nbaseline_roc = roc_auc_score(y_test, y_probs_baseline)\nbaseline_pr = average_precision_score(y_test, y_probs_baseline)\n\nprint(f\"\\n=== SVM Baseline Results ===\")\nprint(f\"Accuracy:          {baseline_acc:.4f}\")\nprint(f\"F1 Score (Up):     {baseline_f1:.4f}\")\nprint(f\"ROC-AUC Score:     {baseline_roc:.4f}\")\nprint(f\"PR-AUC Score:      {baseline_pr:.4f}\")\n\nprint(\"\\nConfusion Matrix:\")\ncm_baseline = confusion_matrix(y_test, y_pred_baseline)\nprint(cm_baseline)\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred_baseline, target_names=['Down (0)', 'Up (1)']))"
  },
  {
   "cell_type": "markdown",
   "id": "342ceafa-1cd1-4ed3-bf29-a9311cf553ba",
   "metadata": {},
   "source": "## 5: Hyperparameter Optimization (Optimized GridSearchCV)\n\n**Performance optimizations applied:**\n1. `probability=False` during search (3-10x faster), refit with `True` only at end\n2. RBF kernel only (gamma is irrelevant for linear, wastes ~50% of combos)\n3. 3-fold TimeSeriesSplit (reduced from 5 - sufficient for class project)\n4. Focused grid: 27 combinations Ã— 3 folds = **81 fits** (down from 320)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bc0a86-1a4c-4bc5-8d16-8535f52fab22",
   "metadata": {},
   "outputs": [],
   "source": "# === OPTIMIZED GRIDSEARCH (Based on performance recommendations) ===\n# Key optimizations:\n# 1. probability=False during search (3-10x faster), refit with True at end\n# 2. Focus on RBF kernel only (gamma irrelevant for linear, wastes combos)\n# 3. Reduced to 3-fold TimeSeriesSplit (sufficient for class project)\n# 4. Smaller, focused grid\n# 5. n_jobs=2 (better than -1 on limited resources due to SVC overhead)\n\ntscv = TimeSeriesSplit(n_splits=3)  # Reduced from 5 to 3\n\n# Focused parameter grid (RBF only, smaller)\nparam_grid = {\n    'C': [0.1, 1, 10],\n    'gamma': ['scale', 'auto', 0.01],\n    'class_weight': [None, 'balanced', {0: 1.0, 1: 2.5}]\n}\n\n# Use F1 score for the minority class as our optimization metric\nf1_scorer = make_scorer(f1_score, pos_label=1)\n\nprint(\"--- Tuning SVM via GridSearchCV (OPTIMIZED) ---\")\nprint(f\"Parameter combinations: {3 * 3 * 3} = 27\")\nprint(f\"With {tscv.n_splits} CV folds = {27 * 3} = 81 model fits\")\nprint(\"(Down from 320 fits - ~75% reduction)\\n\")\n\n# FAST search with probability=False\ngrid = GridSearchCV(\n    SVC(kernel='rbf', probability=False, random_state=RANDOM_STATE),  # probability=False for speed\n    param_grid,\n    cv=tscv,\n    scoring=f1_scorer,\n    n_jobs=2,  # Limited parallelism to avoid overhead\n    verbose=1,\n    refit=True\n)\ngrid.fit(X_train_scaled, y_train)\n\nprint(f\"\\nBest Parameters: {grid.best_params_}\")\nprint(f\"Best CV F1 Score: {grid.best_score_:.4f}\")\n\n# === REFIT best model WITH probability=True for final evaluation ===\nprint(\"\\nRefitting best model with probability=True for ROC-AUC/PR-AUC...\")\nbest_params = grid.best_params_\nbest_model = SVC(\n    kernel='rbf',\n    C=best_params['C'],\n    gamma=best_params['gamma'],\n    class_weight=best_params['class_weight'],\n    probability=True,  # Now enable for final model\n    random_state=RANDOM_STATE\n)\nbest_model.fit(X_train_scaled, y_train)\n\n# Evaluate on Test Set\ny_pred_opt = best_model.predict(X_test_scaled)\ny_probs_opt = best_model.predict_proba(X_test_scaled)[:, 1]\n\nopt_acc = accuracy_score(y_test, y_pred_opt)\nopt_f1 = f1_score(y_test, y_pred_opt, pos_label=1)\nopt_roc = roc_auc_score(y_test, y_probs_opt)\nopt_pr = average_precision_score(y_test, y_probs_opt)\n\nprint(f\"\\n=== SVM Optimized Results (Test Set) ===\")\nprint(f\"Accuracy:          {opt_acc:.4f}\")\nprint(f\"F1 Score (Up):     {opt_f1:.4f}\")\nprint(f\"ROC-AUC Score:     {opt_roc:.4f}\")\nprint(f\"PR-AUC Score:      {opt_pr:.4f}\")\n\nprint(\"\\nConfusion Matrix:\")\ncm_opt = confusion_matrix(y_test, y_pred_opt)\nprint(cm_opt)\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred_opt, target_names=['Down (0)', 'Up (1)']))"
  },
  {
   "cell_type": "markdown",
   "id": "b54901a2-6389-41ed-845e-8469bdb49554",
   "metadata": {},
   "source": [
    "## 6: Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8783f38-861d-4fb0-870e-5de2667c183b",
   "metadata": {},
   "outputs": [],
   "source": "# Create comprehensive comparison DataFrame\ncomparison_data = {\n    'Model': ['SVM Baseline', 'SVM Optimized'],\n    'Accuracy': [baseline_acc, opt_acc],\n    'F1 (Up)': [baseline_f1, opt_f1],\n    'ROC-AUC': [baseline_roc, opt_roc],\n    'PR-AUC': [baseline_pr, opt_pr]\n}\ncomparison_df = pd.DataFrame(comparison_data)\n\n# Calculate improvements\ncomparison_df['Acc Improvement'] = ''\ncomparison_df.loc[1, 'Acc Improvement'] = f\"{(opt_acc - baseline_acc) * 100:+.2f}%\"\ncomparison_df['F1 Improvement'] = ''\ncomparison_df.loc[1, 'F1 Improvement'] = f\"{(opt_f1 - baseline_f1) * 100:+.2f}%\"\n\nprint(\"=\"*70)\nprint(\"MODEL COMPARISON SUMMARY\")\nprint(\"=\"*70)\ndisplay(comparison_df)\n\n# Visualize Comparison - Multiple Metrics\nfig, axes = plt.subplots(1, 4, figsize=(18, 5))\nmetrics = ['Accuracy', 'F1 (Up)', 'ROC-AUC', 'PR-AUC']\ncolors = ['#3498db', '#e74c3c']\n\nfor i, metric in enumerate(metrics):\n    ax = axes[i]\n    values = comparison_df[metric].values\n    bars = ax.bar(['Baseline', 'Optimized'], values, color=colors)\n    ax.set_title(metric, fontsize=12, fontweight='bold')\n    ax.set_ylim(0, max(values) * 1.2)\n    \n    for bar, val in zip(bars, values):\n        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n               f'{val:.3f}', ha='center', va='bottom', fontsize=10)\n\nplt.suptitle('SVM Baseline vs. Optimized Model Performance', fontsize=14, fontweight='bold', y=1.02)\nplt.tight_layout()\nplt.show()\n\n# Confusion Matrix Comparison\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\nax1 = axes[0]\nsns.heatmap(cm_baseline, annot=True, fmt='d', cmap='Blues', ax=ax1,\n            xticklabels=['Down (0)', 'Up (1)'], yticklabels=['Down (0)', 'Up (1)'])\nax1.set_title('Baseline SVM Confusion Matrix')\nax1.set_ylabel('Actual')\nax1.set_xlabel('Predicted')\n\nax2 = axes[1]\nsns.heatmap(cm_opt, annot=True, fmt='d', cmap='Blues', ax=ax2,\n            xticklabels=['Down (0)', 'Up (1)'], yticklabels=['Down (0)', 'Up (1)'])\nax2.set_title('Optimized SVM Confusion Matrix')\nax2.set_ylabel('Actual')\nax2.set_xlabel('Predicted')\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "b692aab5-a07a-4ccc-8365-62ca07314bf0",
   "metadata": {},
   "source": "## 7. Ablation Study: Feature Reduction Analysis\n\nTesting two hypotheses:\n1. **Regional Weather Redundancy**: Removing PA/IL weather features (keeping TX, NY)\n2. **Price Level Redundancy**: Removing contract price levels (keeping curve_spread)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c977e44-df85-493d-af5c-12d8f91f9cd4",
   "metadata": {},
   "outputs": [],
   "source": "# List of features to remove based on redundancy hypotheses\ncols_to_remove = [\n    'CDD_PA', 'CDD_IL', 'HDD_PA', 'HDD_IL',  # Regional weather redundancy\n    'contract_1_price', 'contract_2_price'    # Price levels (keep curve_spread)\n]\n\n# Prepare the reduced dataset\nX_reduced = X.drop(columns=[c for c in cols_to_remove if c in X.columns])\n\nprint(f\"Original features: {X.shape[1]}\")\nprint(f\"Reduced features: {X_reduced.shape[1]}\")\nprint(f\"Removed columns: {[c for c in cols_to_remove if c in X.columns]}\")\nprint(f\"\\nRemaining features: {list(X_reduced.columns)}\")\n\n# Apply same chronological split\nX_train_r, X_test_r = X_reduced[mask_train], X_reduced[mask_test]\n\n# Re-scaling the reduced feature set\nscaler_r = StandardScaler()\nX_train_r_scaled = scaler_r.fit_transform(X_train_r)\nX_test_r_scaled = scaler_r.transform(X_test_r)\n\n# Train optimized SVM on reduced features (using same best params)\nprint(\"\\n--- Training SVM on Reduced Features ---\")\nmodel_reduced = SVC(\n    kernel='rbf',\n    C=best_params['C'],\n    gamma=best_params['gamma'],\n    class_weight=best_params['class_weight'],\n    probability=True,\n    random_state=RANDOM_STATE\n)\nmodel_reduced.fit(X_train_r_scaled, y_train)\n\n# Evaluate\ny_pred_red = model_reduced.predict(X_test_r_scaled)\ny_probs_red = model_reduced.predict_proba(X_test_r_scaled)[:, 1]\n\nred_acc = accuracy_score(y_test, y_pred_red)\nred_f1 = f1_score(y_test, y_pred_red, pos_label=1)\nred_roc = roc_auc_score(y_test, y_probs_red)\nred_pr = average_precision_score(y_test, y_probs_red)\n\n# Create results DataFrame\nablation_results = pd.DataFrame({\n    'Model': ['SVM (Full Features)', 'SVM (Reduced Features)'],\n    'Num Features': [X.shape[1], X_reduced.shape[1]],\n    'Accuracy': [opt_acc, red_acc],\n    'F1 (Up)': [opt_f1, red_f1],\n    'ROC-AUC': [opt_roc, red_roc],\n    'PR-AUC': [opt_pr, red_pr]\n})\n\n# Add difference row\nablation_results['Acc Diff'] = ''\nablation_results.loc[1, 'Acc Diff'] = f\"{(red_acc - opt_acc) * 100:+.2f}%\"\nablation_results['F1 Diff'] = ''\nablation_results.loc[1, 'F1 Diff'] = f\"{(red_f1 - opt_f1) * 100:+.2f}%\"\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"ABLATION STUDY RESULTS\")\nprint(\"=\"*70)\ndisplay(ablation_results)\n\nprint(\"\\nClassification Report (Reduced Features):\")\nprint(classification_report(y_test, y_pred_red, target_names=['Down (0)', 'Up (1)']))"
  },
  {
   "cell_type": "markdown",
   "id": "8b188ccb-71cc-495f-970b-e981b038a9a5",
   "metadata": {},
   "source": "## 8. Final Comparison Visualization"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccfd582-9297-4dc2-879e-a023da58564d",
   "metadata": {},
   "outputs": [],
   "source": "# Create final comparison of all 3 models\nfinal_comparison = pd.DataFrame({\n    'Model': ['SVM Baseline', 'SVM Optimized', 'SVM Reduced Features'],\n    'Features': [X.shape[1], X.shape[1], X_reduced.shape[1]],\n    'Accuracy': [baseline_acc, opt_acc, red_acc],\n    'F1 (Up)': [baseline_f1, opt_f1, red_f1],\n    'ROC-AUC': [baseline_roc, opt_roc, red_roc],\n    'PR-AUC': [baseline_pr, opt_pr, red_pr]\n})\n\nprint(\"=\"*80)\nprint(\"FINAL MODEL COMPARISON (ALL VARIANTS)\")\nprint(\"=\"*80)\ndisplay(final_comparison)\n\n# Visualization - All models comparison\nfig, axes = plt.subplots(1, 4, figsize=(18, 5))\nmetrics = ['Accuracy', 'F1 (Up)', 'ROC-AUC', 'PR-AUC']\ncolors = ['#3498db', '#e74c3c', '#2ecc71']\n\nfor i, metric in enumerate(metrics):\n    ax = axes[i]\n    values = final_comparison[metric].values\n    bars = ax.bar(['Baseline', 'Optimized', 'Reduced'], values, color=colors)\n    ax.set_title(metric, fontsize=12, fontweight='bold')\n    ax.set_ylim(0, max(values) * 1.2)\n    \n    for bar, val in zip(bars, values):\n        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n               f'{val:.3f}', ha='center', va='bottom', fontsize=9)\n\nplt.suptitle('SVM Model Performance Comparison (Binary Classification)', fontsize=14, fontweight='bold', y=1.02)\nplt.tight_layout()\nplt.show()\n\n# Print best parameters\nprint(\"\\n\" + \"=\"*80)\nprint(\"BEST GRIDSEARCHCV PARAMETERS\")\nprint(\"=\"*80)\nfor param, value in grid.best_params_.items():\n    print(f\"  {param}: {value}\")\n\n# Summary\nprint(\"\\n\" + \"=\"*80)\nprint(\"SUMMARY\")\nprint(\"=\"*80)\nprint(f\"\"\"\nThis enhanced SVM notebook incorporates:\n1. Binary target (PriceUp) for next-day direction prediction\n2. Engineered features: curve_spread, storage_change, momentum indicators (ret_1/3/5/10)\n3. Chronological train/test split at {SPLIT_DATE}\n4. TimeSeriesSplit cross-validation (proper for time-series)\n5. GridSearchCV optimizing F1 score (for minority class)\n6. Multiple evaluation metrics: Accuracy, F1, ROC-AUC, PR-AUC\n7. Ablation study with reduced features\n\nBest performing model: {'Optimized' if opt_f1 >= red_f1 else 'Reduced Features'} SVM\nBest F1 Score (Up class): {max(opt_f1, red_f1):.4f}\n\"\"\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}